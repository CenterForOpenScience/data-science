---
title: "preprint_vsds_collection"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# loading required libraries
library(tidyverse)
library(osfr)
library(reticulate)
library(jsonlite)
library(lubridate)

url <- 'https://api.osf.io/_/metrics/preprints/'
osf_auth <- Sys.getenv("osf_preprintimpact_auth")
auth_header <- httr::add_headers('Authorization' = paste('Bearer', osf_auth))

use_condaenv(condaenv = "myenv", conda = "/Users/courtneysoderberg/opt/anaconda3/bin/python")

curr_time <- now('UTC')
yesterday <- as.Date(curr_time) - 1
```

```{r}
# reading in preprint data
new_pp <- read_csv('/Users/courtneysoderberg/Documents/data-science/Sloan_grant/preprint_info.csv') %>% #use absolute path for cron job
              filter(date_published >= yesterday) %>%
              mutate(lt = curr_time,
                     gte = date_published,
                     run_date = as.Date(curr_time),
                     end_date = ymd_hms(curr_time) + days(14))

coi_pp_dc <- read_csv('/Users/courtneysoderberg/Documents/data-science/Sloan_grant/coi_pp_dc.csv') %>%
                filter(end_date >= curr_time,
                       run_date >= yesterday) %>%
                mutate(gte = lt,
                       lt = curr_time,
                       run_date = as.Date(curr_time)) %>%
                bind_rows(new_pp)
```

```{python}
pp = r.new_pp #get pandas df of R object

# set up query for getting views per preprint per user_id in timeframe
query = {
    "query": {
         "term" : { "preprint_id" : "'"guid"'" } # example pp guid
    },
     "aggs" : {
        "download_timeframe": {
            "filter": {
                "range" : {
                    "timestamp" : {
                        "gte" : "'"gte_date"'",
                        "lte" : "'"lt_date"'"
                    }
                }
            },
            "aggs": {
                "users" : {
                    "terms" : {
                        "field" : "user_id",
                        "size" : 5000
                    },
                    "aggs": {
                      "downloads_per_day" : {
                        "date_histogram" :{
                          "field":"timestamp",
                          "interval":"minute",
                          "format": "yyyy-MM-dd HH:mm:ss"
                        }
                      }
                    }
                }
            }
        }
    }
}


payload = {
    'data': {
        'type': 'preprint_metrics',
        'attributes': {
            'query': query
        }
    }
}

res = requests.post(post_url, headers=headers, json=payload)
pp_views_byuser = res.json()['aggregations']['download_timeframe']['users']['buckets']

for i in range(len(pp.guid)):

  # set variable names for each loop
  lt_date = pp.lt.iloc[i]
  gte_date = pp.gte.iloc[i]
  guid = pp.guid.iloc[i]

  
print(pp)
pp.date_published.iloc[2]

len(pp.guid) - 1
range(len(pp.guid))


  print(i)

type(pp)
```

