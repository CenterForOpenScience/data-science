---
title: "preprint_vsds_collection"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# loading required libraries
library(tidyverse)
library(osfr)
library(reticulate)
library(jsonlite)
library(lubridate)

url <- 'https://api.osf.io/_/metrics/preprints/'
osf_auth <- Sys.getenv("osf_preprintimpact_auth")
auth_header <- httr::add_headers('Authorization' = paste('Bearer', osf_auth))

use_condaenv(condaenv = "myenv", conda = "/Users/courtneysoderberg/opt/anaconda3/bin/python")

curr_time <- now('UTC')
yesterday <- as.Date(curr_time) - 1
```

```{r}
# reading in preprint data
new_pp <- read_csv('/Users/courtneysoderberg/Documents/data-science/Sloan_grant/preprint_info.csv') %>% #use absolute path for cron job
              filter(date_published >= yesterday) %>%
              mutate(lt = curr_time,
                     gte = date_published,
                     run_date = as.Date(curr_time),
                     end_date = ymd_hms(curr_time) + days(14))

coi_pp_dc <- read_csv('/Users/courtneysoderberg/Documents/data-science/Sloan_grant/coi_pp_dc.csv') %>%
                filter(end_date >= curr_time,
                       run_date >= yesterday) %>%
                mutate(gte = lt,
                       lt = curr_time,
                       run_date = as.Date(curr_time)) %>%
                bind_rows(new_pp)
```

```{python}
pp = r.new_pp #get pandas df of R object

import requests

METRICS_BASE = r.url
TOKEN = r.osf_auth

headers = {
    'Content-Type': 'application/vnd.api+json',
    'Authorization': 'Bearer {}'.format(TOKEN)
}

post_url = '{}views/'.format(METRICS_BASE)

lt_date = pp.loc[0, 'lt']
gte_date = pp.loc[0, 'gte']
guid = pp.iloc[4,1]

# set up query for getting views per preprint per user_id in timeframe
query = {
    "query": {
         "term" : { "preprint_id" : guid } # example pp guid
    },
     "aggs" : {
        "download_timeframe": {
            "filter": {
                "range" : {
                    "timestamp" : {
                        "gte" : "2020-03-20",
                        "lte" : "2020-03-26"
                    }
                }
            },
            "aggs": {
                "users" : {
                    "terms" : {
                        "field" : "user_id",
                        "size" : 5000
                    },
                    "aggs": {
                      "downloads_per_day" : {
                        "date_histogram" :{
                          "field":"timestamp",
                          "interval":"minute",
                          "format": "yyyy-MM-dd HH:mm:ss"
                        }
                      }
                    }
                }
            }
        }
    }
}


payload = {
    'data': {
        'type': 'preprint_metrics',
        'attributes': {
            'query': query
        }
    }
}

res = requests.post(post_url, headers=headers, json=payload)
pp_views_byuser134 = res.json()['aggregations']['download_timeframe']['users']['buckets']


#for i in range(len(pp.guid)):

  # set variable names for each loop
#  lt_date = pp.loc[i, 'lt']
#  gte_date = pp.loc[i, 'gte']
#  guid = pp.loc[i, 'guid']
  
  

#  payload = {
#      'data': {
#          'type': 'preprint_metrics',
#          'attributes': {
#              'query': query
#         }
#     }
#  }

#  res = requests.post(post_url, headers=headers, json=payload)
#  pp_views_byuser = res.json()['aggregations']['download_timeframe']['users']['buckets']

  
print(pp)
print(guid)
print(guids)
print(lt_date)
```

